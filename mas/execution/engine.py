from __future__ import annotations

import asyncio
import time
import uuid
from logging import Logger
from typing import TYPE_CHECKING, final

from ..agents.pool import AgentPoolRegistry
from ..core.schemas import (
    ExecutionContext,
    HookContext,
    PermissionDecision,
    TaskResult,
    TaskStatus,
    WorkflowResult,
)
from ..core.task import Task
from ..core.workflow import Workflow
from ..hooks.manager import HookManager
from ..llm.client import LLMClient
from ..logging.events import LogEvent
from ..logging.tracker import ExecutionTracker
from ..utils.logger import get_logger
from ..permissions.manager import PermissionManager
from .runner import TaskRunner
from .scheduler import TaskScheduler

if TYPE_CHECKING:
    from ..core.schemas import AgentDescriptor


@final
class ExecutionEngine:
    """Workflow execution engine with LLM and Hooks integration."""

    llm_client: LLMClient
    hook_manager: HookManager
    permission_manager: PermissionManager
    scheduler: TaskScheduler
    runner: TaskRunner
    agent_pool: AgentPoolRegistry
    _session_id: str
    verbose: bool
    tracker: ExecutionTracker
    _logger: Logger

    def __init__(
        self,
        llm_client: LLMClient | None = None,
        hook_manager: HookManager | None = None,
        permission_manager: PermissionManager | None = None,
        scheduler: TaskScheduler | None = None,
        runner: TaskRunner | None = None,
        verbose: bool = False,
    ) -> None:
        llm_client = llm_client or LLMClient()
        hook_manager = hook_manager or HookManager()
        permission_manager = permission_manager or PermissionManager()
        scheduler = scheduler or TaskScheduler()
        runner = runner or TaskRunner()
        agent_pool = AgentPoolRegistry()
        session_id = str(uuid.uuid4())
        tracker = ExecutionTracker(session_id)
        logger = get_logger("mas.execution")

        self.llm_client: LLMClient = llm_client
        self.hook_manager: HookManager = hook_manager
        self.permission_manager: PermissionManager = permission_manager
        self.scheduler: TaskScheduler = scheduler
        self.runner: TaskRunner = runner
        self.agent_pool: AgentPoolRegistry = agent_pool
        self._session_id: str = session_id
        self.verbose: bool = verbose
        self.tracker: ExecutionTracker = tracker
        self._logger = logger

    async def run(self, workflow: Workflow) -> WorkflowResult:
        """Execute the workflow and return results."""
        task_results: dict[str, TaskResult] = {}
        errors: dict[str, str] = {}

        context = ExecutionContext(
            original_task="",
            current_agent="",
            session_id=self._session_id,
        )

        self.tracker.log_workflow_start(workflow.description)
        if self.verbose:
            self._print_workflow_start(workflow)

        while True:
            ready_tasks = self.scheduler.get_ready_tasks(workflow)
            if not ready_tasks:
                if not self.scheduler.has_pending_tasks(workflow):
                    break
                break

            runner_results = await asyncio.gather(
                *[self.runner.run(task) for task in ready_tasks],
                return_exceptions=True,
            )
            if runner_results:
                for runner_result in runner_results:
                    if isinstance(runner_result, Exception):
                        self._logger.warning(
                            "Runner error",
                            extra={"task_id": "unknown", "error": str(runner_result)},
                        )
                self._logger.debug(
                    "Runner results captured", extra={"count": len(runner_results)}
                )
                _unused = runner_results
                if _unused:
                    self._logger.debug(
                        "Runner results processed", extra={"count": len(_unused)}
                    )

            llm_results = await asyncio.gather(
                *[self._execute_task(task, context, task_results) for task in ready_tasks],
                return_exceptions=True,
            )

            for task, result in zip(ready_tasks, llm_results):
                if isinstance(result, Exception):
                    error_msg = str(result)
                    end_time = time.time()
                    task.mark_failed(error_msg, end_time=end_time)
                    errors[task.task_id] = error_msg
                    task_results[task.task_id] = TaskResult(
                        task_id=task.task_id,
                        success=False,
                        error=error_msg,
                        end_time=end_time,
                    )
                    if self.verbose:
                        self._print_task_error(task.task_id, error_msg)
                elif isinstance(result, TaskResult):
                    if result.success:
                        task.mark_completed(result)
                    else:
                        task.mark_failed(
                            result.error or "Unknown error",
                            start_time=result.start_time,
                            end_time=result.end_time,
                            agent_name=result.agent_name,
                        )
                        errors[task.task_id] = result.error or "Unknown error"
                    task_results[task.task_id] = result
                    if self.verbose:
                        self._print_task_end(result)

        # Check for incomplete tasks
        for task_id, task in workflow.tasks.items():
            if task.status != TaskStatus.COMPLETED and task_id not in errors:
                errors[task_id] = "Task not completed (dependency failed)"

        success = len(errors) == 0
        workflow_result = WorkflowResult(
            success=success,
            task_results=task_results,
            errors=errors,
            session_id=self._session_id,
        )
        self.tracker.log_workflow_end(workflow_result)
        workflow_result.total_duration_ms = self._get_total_duration_ms()
        if self.verbose:
            self._print_workflow_end(workflow_result)

        return workflow_result

    async def _execute_task(
        self,
        task: Task,
        context: ExecutionContext,
        task_results: dict[str, TaskResult],
    ) -> TaskResult:
        """Execute a single task with hooks and LLM."""
        task.mark_running()
        start_time = time.time()

        # Select agent for this task
        try:
            agent = self.agent_pool.select_best_agent(task.capability, {})
        except LookupError:
            # No agent found, use default execution
            agent = None

        agent_name = agent.name if agent else "default"
        context.current_agent = agent_name
        self.tracker.log_agent_selected(task.task_id, agent_name)
        self.tracker.log_task_start(task.task_id, agent_name)
        if self.verbose:
            self._print_task_start(task.task_id, agent_name)

        # Create hook context
        hook_context = HookContext(
            agent_name=agent_name,
            tool_name="llm_call",
            params={"task_id": task.task_id, "objective": task.objective},
            session_id=self._session_id,
            timestamp=time.time(),
        )

        # Execute PreToolUse hooks
        pre_result = await self.hook_manager.execute_pre_tool_use(hook_context)
        self.tracker.log_hook_executed(
            task.task_id,
            agent_name,
            hook_context.tool_name,
            pre_result.decision.value,
            pre_result.message,
        )
        if pre_result.decision == PermissionDecision.DENY:
            result = TaskResult(
                task_id=task.task_id,
                success=False,
                error=f"Hook denied: {pre_result.message}",
                start_time=start_time,
                end_time=time.time(),
                agent_name=agent_name,
            )
            self.tracker.log_task_end(task.task_id, result)
            return result

        # Execute LLM call
        try:
            # Collect dependency outputs for context
            dependency_outputs: dict[str, str] = {}
            for dep_id in task.dependencies:
                if dep_id in task_results and task_results[dep_id].output:
                    dependency_outputs[dep_id] = str(task_results[dep_id].output)

            output = await self._call_llm(task, agent, dependency_outputs)
        except Exception as e:
            # Execute OnError hooks
            hook_result = await self.hook_manager.execute_on_error(hook_context)
            _ = hook_result
            if hook_result.decision != PermissionDecision.ALLOW:
                self._logger.warning(
                    "OnError hook executed",
                    extra={
                        "task_id": task.task_id,
                        "agent": agent_name,
                        "decision": hook_result.decision.value,
                    },
                )
            result = TaskResult(
                task_id=task.task_id,
                success=False,
                error=f"LLM call failed: {e}",
                start_time=start_time,
                end_time=time.time(),
                agent_name=agent_name,
            )
            self.tracker.log_error(task.task_id, e)
            self.tracker.log_task_end(task.task_id, result)
            return result

        # Execute PostToolUse hooks
        post_result = await self.hook_manager.execute_post_tool_use(
            hook_context, output
        )
        self.tracker.log_hook_executed(
            task.task_id,
            agent_name,
            hook_context.tool_name,
            post_result.decision.value,
            post_result.message,
        )
        if post_result.decision == PermissionDecision.DENY:
            result = TaskResult(
                task_id=task.task_id,
                success=False,
                error=f"Post-hook denied: {post_result.message}",
                start_time=start_time,
                end_time=time.time(),
                agent_name=agent_name,
            )
            self.tracker.log_task_end(task.task_id, result)
            return result

        result = TaskResult(
            task_id=task.task_id,
            success=True,
            output=output,
            metadata={"agent": agent_name},
            start_time=start_time,
            end_time=time.time(),
            agent_name=agent_name,
        )
        self.tracker.log_task_end(task.task_id, result)
        return result

    async def _call_llm(
        self,
        task: Task,
        agent: AgentDescriptor | None,
        dependency_outputs: dict[str, str],
    ) -> str:
        """Call LLM with the task and agent configuration.

        Args:
            task: The task to execute
            agent: The agent descriptor (or None for default)
            dependency_outputs: Outputs from dependency tasks for context
        """
        if agent:
            system_prompt = agent.system_prompt
            model = agent.model
            temperature = agent.temperature
            agent_name = agent.name
        else:
            system_prompt = "You are a helpful assistant."
            model = None
            temperature = 0.7
            agent_name = "default"

        # Build context from dependency outputs
        context_section = ""
        if dependency_outputs:
            context_parts = []
            for dep_id, dep_output in dependency_outputs.items():
                # Truncate very long outputs to avoid token limits
                truncated = dep_output[:8000] if len(dep_output) > 8000 else dep_output
                context_parts.append(f"### {dep_id} ä»»åŠ¡çš„è¾“å‡º:\n{truncated}")
            context_section = "\n\n## å‰ç½®ä»»åŠ¡çš„è¾“å‡ºï¼ˆè¯·åŸºäºè¿™äº›å†…å®¹å®Œæˆå½“å‰ä»»åŠ¡ï¼‰:\n\n" + "\n\n".join(context_parts)

        prompt = f"""System: {system_prompt}
{context_section}

## å½“å‰ä»»åŠ¡:
{task.objective}

è¯·åŸºäºå‰ç½®ä»»åŠ¡çš„è¾“å‡ºï¼ˆå¦‚æœæœ‰ï¼‰å®Œæˆå½“å‰ä»»åŠ¡ï¼Œå¹¶æä¾›ä½ çš„å›ç­”ã€‚"""

        self.tracker.log_llm_request(task.task_id, agent_name, prompt)
        try:
            response = await self.llm_client.acomplete(
                prompt=prompt,
                model=model,
                temperature=temperature,
            )
            self.tracker.log_llm_response(task.task_id, agent_name, response)
            return response
        except ValueError as e:
            # API key not set - return placeholder for testing
            if "MINIMAX_API_KEY" in str(e):
                response = f"[Placeholder: Task '{task.task_id}' completed - API key not configured]"
                self.tracker.log_llm_response(task.task_id, agent_name, response)
                return response
            raise

    @staticmethod
    def _ignore_runner_results(_results: list[TaskResult | BaseException]) -> None:
        return None

    @staticmethod
    def _ignore_hook_result(_result: object) -> None:
        return None

    def _get_total_duration_ms(self) -> float | None:
        for record in reversed(self.tracker.records):
            if record.event == LogEvent.WORKFLOW_END:
                return record.duration_ms
        return None

    def _print_workflow_start(self, workflow: Workflow) -> None:
        timestamp = time.strftime("%H:%M:%S", time.localtime())
        print(f"[{timestamp}] ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow.description}")

    def _print_task_start(self, task_id: str, agent_name: str) -> None:
        timestamp = time.strftime("%H:%M:%S", time.localtime())
        print(f"[{timestamp}] â”œâ”€ ä»»åŠ¡ [{task_id}] å¼€å§‹ ({agent_name})")

    def _print_task_end(self, result: TaskResult) -> None:
        timestamp = time.strftime("%H:%M:%S", time.localtime())
        duration = None
        if result.start_time is not None and result.end_time is not None:
            duration = result.end_time - result.start_time
        summary = ""
        if result.output is not None:
            summary = self._truncate_output(str(result.output))
        status = "âœ…" if result.success else "âŒ"
        duration_text = f" ({duration:.1f}s)" if duration is not None else ""
        print(f"[{timestamp}] â”‚  â””â”€ {status} å®Œæˆ{duration_text} - {summary}")

    def _print_task_error(self, task_id: str, error: str) -> None:
        timestamp = time.strftime("%H:%M:%S", time.localtime())
        summary = self._truncate_output(error)
        print(f"[{timestamp}] â”‚  â””â”€ âŒ {task_id} å¤±è´¥ - {summary}")

    def _print_workflow_end(self, result: WorkflowResult) -> None:
        timestamp = time.strftime("%H:%M:%S", time.localtime())
        total_duration = result.total_duration_ms
        duration_text = ""
        if total_duration is not None:
            duration_text = f" (æ€»è€—æ—¶: {total_duration / 1000:.1f}s)"
        print(f"[{timestamp}] â””â”€ å·¥ä½œæµå®Œæˆ{duration_text}")

    def _truncate_output(self, output: str) -> str:
        if len(output) <= 50:
            return output
        return f"{output[:50]}..."
